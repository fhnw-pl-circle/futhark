{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook assumes GPU support and pyopencl installed and set up correctly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matmul\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pyopencl\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = matmul.matmul()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyopencl.Device 'NVIDIA GeForce GTX 1650 Ti' on 'NVIDIA CUDA' at 0x263a920>\n",
      "(1024, 512) int32\n"
     ]
    }
   ],
   "source": [
    "n = 1024\n",
    "m = 512\n",
    "p = 1024\n",
    "A_host = np.random.randint(0,1000, size=(n,m), dtype=np.int32)\n",
    "B_host = np.random.randint(0,1000, size=(m,p), dtype=np.int32)\n",
    "\n",
    "print(o.queue.device)\n",
    "A_device = pyopencl.array.to_device(o.queue, A_host)\n",
    "B_device = pyopencl.array.to_device(o.queue, B_host)\n",
    "C_device = pyopencl.array.empty(o.queue, (n,p), np.int32)\n",
    "pyopencl.enqueue_barrier(o.queue).wait()\n",
    "o.queue.finish()\n",
    "\n",
    "print(A_device.shape, A_device.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 1024) int32\n"
     ]
    }
   ],
   "source": [
    "C_device2 = o.matmul(A_device, B_device)\n",
    "C_host2 = C_device2.get()\n",
    "print(C_host2.shape, C_host2.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 1024) int32\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "C_np = np.matmul(A_host, B_host)\n",
    "print(C_np.shape, C_np.dtype)\n",
    "print(np.array_equal(C_host2, C_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/stefanv/PyOpenCL/blob/master/examples/matrix-multiply.py\n",
    "with open('matmul.cl', 'r') as file:\n",
    "    program_opencl = file.read()\n",
    "\n",
    "block_size = 16\n",
    "kernel_params = {\"block_size\": block_size,\n",
    "        \"w_a\":m, \"h_a\":n, \"w_b\":p}\n",
    "\n",
    "prg = pyopencl.Program(o.ctx, program_opencl % kernel_params).build(options=\"-cl-mad-enable -cl-fast-relaxed-math\")\n",
    "kernel = prg.matrixMul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 1024) int32\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "event = kernel(o.queue, C_device.shape, (block_size, block_size), \n",
    "            C_device.data, A_device.data, B_device.data)\n",
    "event.wait()\n",
    "C_host = C_device.get()\n",
    "print(C_host.shape, C_host.dtype)\n",
    "print(np.array_equal(C_host, C_host2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opencl time compute (host) 3.014 ms\n",
      "opencl time download (host) 1.641 ms\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "# warmup ----------------------------------------------------------------------\n",
    "for i in range(5):\n",
    "    event = kernel(o.queue, C_device.shape, (block_size, block_size), \n",
    "            C_device.data, A_device.data, B_device.data)\n",
    "    event.wait()\n",
    "\n",
    "o.queue.finish()\n",
    "\n",
    "# actual benchmark ------------------------------------------------------------\n",
    "t1 = time()\n",
    "\n",
    "count = 1000\n",
    "for i in range(count):\n",
    "    event = kernel(o.queue, C_device.shape, (block_size, block_size), \n",
    "            C_device.data, A_device.data, B_device.data)\n",
    "\n",
    "#event.wait()\n",
    "o.queue.finish()\n",
    "\n",
    "gpu_time = (time()-t1)/count\n",
    "\n",
    "# transfer device -> host -----------------------------------------------------\n",
    "t1 = time()\n",
    "foo = C_device.get()\n",
    "pull_time = time()-t1\n",
    "\n",
    "print(f\"opencl time compute (host) {(gpu_time * 1000):.3f} ms\")\n",
    "print(f\"opencl time download (host) {(pull_time * 1000):.3f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "futhark time compute (host) 1.499 ms\n",
      "futhark time download (host) 1.617 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# warmup ----------------------------------------------------------------------\n",
    "for i in range(5):\n",
    "    C_device2 = o.matmul(A_device, B_device)\n",
    "\n",
    "o.queue.finish()\n",
    "\n",
    "# actual benchmark ------------------------------------------------------------\n",
    "t1 = time()\n",
    "\n",
    "count = 1000\n",
    "for i in range(count):\n",
    "    C_device2 = o.matmul(A_device, B_device)\n",
    "\n",
    "o.queue.finish()\n",
    "\n",
    "gpu_time = (time()-t1)/count\n",
    "\n",
    "# transfer device -> host -----------------------------------------------------\n",
    "t1 = time()\n",
    "foo = C_device2.get()\n",
    "pull_time = time()-t1\n",
    "\n",
    "print(f\"futhark time compute (host) {(gpu_time * 1000):.3f} ms\")\n",
    "print(f\"futhark time download (host) {(pull_time * 1000):.3f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with: `futhark bench matmul.fut --backend=opencl`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
